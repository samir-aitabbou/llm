# Use the official Apache Airflow image as the base image
FROM apache/airflow:2.6.0-python3.9

# Switch to the root user to install additional packages
USER root

# Install Java and procps (for ps command)
RUN apt-get update && \
    apt-get install -y openjdk-11-jdk-headless procps && \
    rm -rf /var/lib/apt/lists/*

# Set JAVA_HOME environment variable
ENV JAVA_HOME /usr/lib/jvm/java-11-openjdk-amd64
ENV PATH $JAVA_HOME/bin:$PATH

# Download and install Apache Spark
ARG SPARK_VERSION=3.5.1
ARG HADOOP_VERSION=3
RUN curl -sL "https://archive.apache.org/dist/spark/spark-${SPARK_VERSION}/spark-${SPARK_VERSION}-bin-hadoop${HADOOP_VERSION}.tgz" | tar -xz -C /opt/
RUN ln -s /opt/spark-${SPARK_VERSION}-bin-hadoop${HADOOP_VERSION} /opt/spark

# Set SPARK_HOME environment variable
ENV SPARK_HOME /opt/spark
ENV PATH $SPARK_HOME/bin:$SPARK_HOME/sbin:$PATH


# Switch back to the Airflow user
USER airflow
